{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "def create_gif(time_series, saving_directory, name_file = 'concentration', delete_imgs=False, normalize = True):\n",
    "    time_series_min = time_series.min()\n",
    "    time_series_max = time_series.max()\n",
    "    if time_series.ndim > 3:\n",
    "        #error:\n",
    "        print('Error: The time series should be (time, height, width)')\n",
    "        return\n",
    "    if not os.path.exists(saving_directory + '/img_for_gif'):\n",
    "        os.makedirs(saving_directory + '/img_for_gif')\n",
    "    images = []\n",
    "    cmap = 'magma' #'RdBu_r' #'viridis'\n",
    "    for i in range(time_series.shape[0]):\n",
    "        if normalize:\n",
    "            plt.imshow(time_series[i], origin='lower',cmap=cmap, vmin=time_series_min, vmax=time_series_max);\n",
    "        else:\n",
    "            plt.imshow(time_series[i], cmap=cmap, origin='lower')#, vmin=time_series_min, vmax=time_series_max);\n",
    "        #plt.show()\n",
    "        plt.axis('off')\n",
    "        plt.savefig(saving_directory + f'/img_for_gif/time_series_{i}.png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "        images.append(imageio.imread(saving_directory + f'/img_for_gif/time_series_{i}.png'))\n",
    "\n",
    "    imageio.mimsave(saving_directory + '/' + name_file + '.gif', images, duration=0.1)\n",
    "    if delete_imgs:\n",
    "        shutil.rmtree(saving_directory + '/img_for_gif')\n",
    "\n",
    "\n",
    "\n",
    "create_gif(traj_toplot, 'gif', name_file='density_unnormalized', delete_imgs=True, normalize = False)\n",
    "#save figure without axes and titles:\n",
    "\n",
    "image_name = 'MHD_density_unnormalized'\n",
    "path_to_save = '/mnt/home/polymathic/ceph/the_well/viz/'\n",
    "fig.savefig(f'{path_to_save}{image_name}.png', bbox_inches='tight', pad_inches=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gif(A[traj], 'gif', name_file='concentration_A_normalized', delete_imgs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "def create_gif(time_series, saving_directory, name_file = 'concentration', delete_imgs=False, normalize = True):\n",
    "    time_series_min = time_series.min()\n",
    "    time_series_max = time_series.max()\n",
    "    if time_series.ndim > 3:\n",
    "        #error:\n",
    "        print('Error: The time series should be (time, height, width)')\n",
    "        return\n",
    "    if not os.path.exists(saving_directory + '/img_for_gif'):\n",
    "        os.makedirs(saving_directory + '/img_for_gif')\n",
    "    images = []\n",
    "    cmap = 'magma' #'RdBu_r' #'viridis'\n",
    "    for i in range(time_series.shape[0]):\n",
    "        if normalize:\n",
    "            plt.imshow(time_series[i], origin='lower',cmap=cmap, norm =norm)#vmin=time_series_min, vmax=time_series_max);\n",
    "        else:\n",
    "            plt.imshow(time_series[i], cmap=cmap, origin='lower')#, vmin=time_series_min, vmax=time_series_max);\n",
    "        #plt.show()\n",
    "        plt.axis('off')\n",
    "        plt.savefig(saving_directory + f'/img_for_gif/time_series_{i}.png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "        images.append(imageio.imread(saving_directory + f'/img_for_gif/time_series_{i}.png'))\n",
    "\n",
    "    imageio.mimsave(saving_directory + '/' + name_file + '.gif', images, duration=0.1)\n",
    "    if delete_imgs:\n",
    "        shutil.rmtree(saving_directory + '/img_for_gif')\n",
    "create_gif(traj_toplot, 'gif', name_file='Ye_unnormalized', delete_imgs=True, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset checker\n",
    "\n",
    "#Check dataset\n",
    "#TEST\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def check_dimensions(f):\n",
    "    \"\"\"Check that the dimensions group of the file\n",
    "    is in the correct format for the well dataset\"\"\"\n",
    "    print('Checking the formatting of \"dimensions\" group')\n",
    "    dims = f[\"dimensions\"]\n",
    "    assert \"time\" in dims, \"Group 'dimensions must contain a 'time' dataset\"\n",
    "    assert (\n",
    "        \"sample_varying\" in dims[\"time\"].attrs\n",
    "    ), \"Dataset 'time' must have a 'sample_varying' attribute\"\n",
    "    assert isinstance(dims['time'].attrs[\"sample_varying\"], (bool, np.bool_)), \"Dataset 'time' must have a 'sample_varying' attribute of type bool\"\n",
    "    assert (\n",
    "        \"spatial_dims\" in dims.attrs\n",
    "    ), \"Group 'dimensions' must contain a 'spatial_dims' attribute\"\n",
    "    assert isinstance(dims.attrs[\"spatial_dims\"], (list, np.ndarray)), \"Attribute 'spatial_dims' must be a list\"\n",
    "    assert isinstance(dims.attrs[\"spatial_dims\"][0], str), \"Attribute 'spatial_dims' must be a list of strings\"\n",
    "    assert (\n",
    "        len(dims.attrs[\"spatial_dims\"]) == f.attrs[\"n_spatial_dims\"]\n",
    "    ), \"Mismatch between n_spatial_dims and spatial_dims\"\n",
    "    assert f.attrs[\"n_spatial_dims\"] > 0, \"Attribute 'n_spatial_dims' must be greater than 0\"\n",
    "    # Check if all spatial dimensions have corresponding datasets\n",
    "    for d in dims.attrs[\"spatial_dims\"]:\n",
    "        assert d in dims, f\"Dimension {d} not found in 'dimensions' group\"\n",
    "        assert (\n",
    "            \"sample_varying\" in dims[d].attrs\n",
    "        ), f\"Dimension {d} must have a 'sample_varying' attribute\"\n",
    "        assert isinstance(\n",
    "            dims[d].attrs[\"sample_varying\"], (bool, np.bool_)\n",
    "        ), f\"Dimension {d} must have a 'sample_varying' attribute of type bool\"\n",
    "        \n",
    "        assert (\n",
    "            \"time_varying\" in dims[d].attrs\n",
    "        ), f\"Dimension {d} must have a 'time_varying' attribute\"\n",
    "        assert isinstance(\n",
    "            dims[d].attrs[\"time_varying\"], (bool, np.bool_)\n",
    "        ), f\"Dimension {d} must have a 'time_varying' attribute of type bool\"\n",
    "    print('Dimensions passed!')\n",
    "\n",
    "\n",
    "def check_fields(f, tensor_order):\n",
    "    \"\"\"Check that the fields group of the file\n",
    "    is in the correct format for the well dataset\"\"\"\n",
    "    group = f\"t{tensor_order}_fields\"\n",
    "    print(f'Checking the formatting of {group} group!')\n",
    "    fields = f[group]\n",
    "    dimensions = f[\"dimensions\"]\n",
    "    spatial_dims = dimensions.attrs[\"spatial_dims\"]\n",
    "    # Check field names are set up\n",
    "    assert \"field_names\" in fields.attrs, \"Group must contain a 'field_names' attribute\"\n",
    "    assert isinstance(fields.attrs[\"field_names\"], (list, np.ndarray)), \"Attribute 'field_names' must be a list\"\n",
    "    if len(fields.attrs[\"field_names\"]) > 0:\n",
    "        assert isinstance(fields.attrs[\"field_names\"][0], str), \"Attribute 'field_names' must be a list of strings\"\n",
    "    # Check each field is set up\n",
    "    for field in fields.attrs[\"field_names\"]:\n",
    "        # Check if the field is defined, then check for boolean flags sample and time varying and list of booleans dim_varying\n",
    "        dim_count = 0\n",
    "        assert field in fields, f\"Field {field} named, but not found in {group} group\"\n",
    "        # Sample dimension checking\n",
    "        assert (\n",
    "            \"sample_varying\" in fields[field].attrs\n",
    "        ), f\"Dataset {field} must have a 'sample_varying' attribute\"\n",
    "        assert isinstance(\n",
    "            fields[field].attrs[\"sample_varying\"], (bool, np.bool_)\n",
    "        ), f\"Dataset {field} must have a 'sample_varying' attribute of type bool\"\n",
    "        if fields[field].attrs[\"sample_varying\"]:\n",
    "            assert fields[field].shape[0] == f.attrs[\"n_trajectories\"], f\"Sample dimension size does not match field {field} size\"\n",
    "            dim_count += 1\n",
    "        # Time dimension checking\n",
    "        assert (\n",
    "            \"time_varying\" in fields[field].attrs\n",
    "        ), f\"Dataset {field} must have a 'time_varying' attribute\"\n",
    "        assert isinstance(\n",
    "            fields[field].attrs[\"time_varying\"], (bool, np.bool_)\n",
    "        ), f\"Dataset {field} must have a 'time_varying' attribute of type bool\"\n",
    "        if fields[field].attrs[\"time_varying\"]:\n",
    "            assert fields[field].shape[dim_count] == dimensions[\"time\"].shape[-1], f\"Time dimension size does not match field {field} size\"\n",
    "            dim_count += 1\n",
    "        # Space dimension checking\n",
    "        assert (\n",
    "            \"dim_varying\" in fields[field].attrs\n",
    "        ), f\"Dataset {field} must have a 'dim_varying' attribute\"\n",
    "        assert isinstance(\n",
    "            fields[field].attrs[\"dim_varying\"], (list, np.ndarray)\n",
    "        ), f\"Dataset {field} must have a 'dim_varying' attribute of type list\"\n",
    "        assert (\n",
    "            len(fields[field].attrs[\"dim_varying\"]) == len(spatial_dims)\n",
    "        ), f\"Dataset {field} must have a 'dim_varying' attribute of length n_spatial_dims\"\n",
    "        assert isinstance(\n",
    "            fields[field].attrs[\"dim_varying\"][0], (bool, np.bool_)\n",
    "        ), f\"Dataset {field} must have a 'dim_varying' list with bool entries\"\n",
    "        for i, dim in enumerate(spatial_dims):\n",
    "            if fields[field].attrs[\"dim_varying\"][i]:\n",
    "                print(dim, fields[field].shape[dim_count])\n",
    "                print(dimensions[dim].shape[-1])\n",
    "                print(dim_count)\n",
    "                assert dimensions[dim].shape[-1] == fields[field].shape[dim_count], f\"Dimension {dim} size does not match field {field} size\"\n",
    "                dim_count += 1\n",
    "    print(f'Fields in {group} passed!')\n",
    "\n",
    "def check_scalars(f):\n",
    "    print('Checking the formatting of \"scalars\" group')\n",
    "    scalars = f[\"scalars\"]\n",
    "    assert \"field_names\" in scalars.attrs, \"Group must contain a 'scalar_names' attribute\"\n",
    "    assert isinstance(scalars.attrs[\"field_names\"], (list, np.ndarray)), \"Attribute 'scalar_names' must be a list\"\n",
    "    if len(scalars.attrs[\"field_names\"]) > 0:\n",
    "        assert isinstance(scalars.attrs[\"field_names\"][0], str), \"Attribute 'scalar_names' must be a list of strings\"\n",
    "    for field in scalars.attrs[\"field_names\"]:\n",
    "        assert field in scalars, f\"Field {field} named, but not found in 'scalars' group\"\n",
    "        assert \"sample_varying\" in scalars[field].attrs, f\"Dataset {field} must have a 'sample_varying' attribute\"\n",
    "        assert isinstance(scalars[field].attrs[\"sample_varying\"], (bool, np.bool_)), f\"Dataset {field} must have a 'sample_varying' attribute of type bool\"\n",
    "        assert \"time_varying\" in scalars[field].attrs, f\"Dataset {field} must have a 'time_varying' attribute\"\n",
    "        assert isinstance(scalars[field].attrs[\"time_varying\"], (bool, np.bool_)), f\"Dataset {field} must have a 'time_varying' attribute of type bool\"\n",
    "        dim_count = scalars[field].attrs[\"sample_varying\"] + scalars[field].attrs[\"time_varying\"]\n",
    "        assert len(scalars[field].shape) == dim_count, f\"Dataset {field} must have {dim_count} dimensions\"\n",
    "    print('Scalars passed!')\n",
    "\n",
    "def check_boundary_conditions(f):\n",
    "    print('Checking the formatting of \"boundary_conditions\" group')\n",
    "    bcs = f[\"boundary_conditions\"]\n",
    "    dimensions = f[\"dimensions\"]\n",
    "    spatial_dims = dimensions.attrs[\"spatial_dims\"]\n",
    "    for key in f[\"boundary_conditions\"]:\n",
    "        bc = bcs[key]\n",
    "        assert 'bc_type' in bc.attrs, \"Group must contain a 'bc_type' attribute\"\n",
    "        assert \"sample_varying\" in bc.attrs, \"Group must contain a 'sample_varying' attribute\"\n",
    "        assert isinstance(bc.attrs[\"sample_varying\"], (bool, np.bool_)), \"Attribute 'sample_varying' must be a boolean\"\n",
    "        assert \"time_varying\" in bc.attrs, \"Group must contain a 'time_varying' attribute\"\n",
    "        assert isinstance(bc.attrs[\"time_varying\"], (bool, np.bool_)), \"Attribute 'time_varying' must be a boolean\"\n",
    "        assert \"associated_fields\" in bc.attrs, \"Group must contain a 'associated_fields' attribute\"\n",
    "        dim_count = bc.attrs[\"sample_varying\"] + bc.attrs[\"time_varying\"]\n",
    "        assert \"associated_dims\" in bc.attrs, \"Group must contain a 'associated_dims' attribute\"\n",
    "        assert isinstance(bc.attrs[\"associated_dims\"], (list, np.ndarray)), \"Attribute 'associated_dims' must be a list\"\n",
    "        assert 'mask' in bc, \"Group must contain a 'mask' dataset\"\n",
    "        assert len(bc.attrs[\"associated_dims\"]) > 0, \"Attribute 'associated_dims' must have at least one entry\"\n",
    "        for i, dim in enumerate(bc.attrs[\"associated_dims\"]):\n",
    "            assert dim in spatial_dims, f\"Dimension {dim} not found in 'spatial_dims'\"\n",
    "            assert bc['mask'].shape[dim_count+i] == dimensions[dim].shape[-1], f\"Dimension {dim} size does not match mask size\"\n",
    "    print('Boundary conditions passed!')\n",
    "\n",
    "def check_hdf5_format(path: str):\n",
    "    \"\"\"Check that the HDF5 file is in the correct format for the well dataset\"\"\"\n",
    "    with h5.File(path, \"r\") as f:\n",
    "        # Start by checking top level attributes\n",
    "        print('Checking top level attributes')\n",
    "        assert \"n_spatial_dims\" in f.attrs, \"n_spatial_dims is required root attribute\"\n",
    "        assert isinstance(int(f.attrs['n_spatial_dims']), (int, np.integer)), \"n_spatial_dims must be an integer\"\n",
    "        assert \"n_trajectories\" in f.attrs, \"n_trajectories is required root attribute\"\n",
    "        assert isinstance(f.attrs['n_trajectories'], (int, np.integer)), \"n_trajectories must be an integer\"\n",
    "        assert \"dataset_name\" in f.attrs, \"dataset_name is required root attribute\"\n",
    "        assert isinstance(f.attrs['dataset_name'], str), \"dataset_name must be a string\"\n",
    "        assert \"grid_type\" in f.attrs, \"grid_type is required root attribute\"\n",
    "        assert isinstance(f.attrs['grid_type'], str), \"grid_type must be a string\"\n",
    "        assert (\n",
    "            \"simulation_parameters\" in f.attrs\n",
    "        ), \"simulation_parameters is required root attribute\"\n",
    "        for sim_param in f.attrs[\"simulation_parameters\"]:\n",
    "            assert (\n",
    "                sim_param in f.attrs\n",
    "            ), f\"Every listed simulation parameter should be included at attribute\"\n",
    "        print('Top level attributes passed!')\n",
    "        assert \"dimensions\" in f, \"No dimensions group found in HDF5 file\"\n",
    "        check_dimensions(f)\n",
    "        for i in range(3):\n",
    "            assert f\"t{i}_fields\" in f, f\"No t{i}_fields group found in HDF5 file\"\n",
    "            check_fields(f, i)\n",
    "        assert \"scalars\" in f, \"No scalars found in HDF5 file\"\n",
    "        check_scalars(f)\n",
    "        assert \"boundary_conditions\" in f, \"No boundary_conditions found in HDF5 file\"\n",
    "        check_boundary_conditions(f)\n",
    "        print(\"HDF5 file validation passed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/mnt/home/polymathic/ceph/the_well/datasets/viscoelastic_instability/data/test/viscoelastic_instability_EIT.hdf5'\n",
    "check_hdf5_format(p)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
